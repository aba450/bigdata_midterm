{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"take_home\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.clustering import KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read .format(\"csv\").option(\"header\", \"true\").load(\"drive_stats_2019_Q1/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select=df.distinct().select('model','serial_number','smart_1_normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model', 'serial_number', 'smart_1_normalized']\n"
     ]
    }
   ],
   "source": [
    "# printing all the columns in the data frame\n",
    "print(df_select.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tried with the complete data set but it was giving some gc overhead error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select=df_select.orderBy(rand()).limit(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+------------------+\n",
      "|               model| serial_number|smart_1_normalized|\n",
      "+--------------------+--------------+------------------+\n",
      "|         ST4000DM000|      Z302715R|               120|\n",
      "|HGST HMS5C4040BLE640|PL2331LAHBTVUJ|               100|\n",
      "|        ST8000NM0055|      ZA13WRL1|                81|\n",
      "|        ST8000NM0055|      ZA16RT31|                81|\n",
      "|         ST4000DM000|      Z30250EB|               117|\n",
      "+--------------------+--------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_select.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col = ['smart_1_normalized']\n",
    "for columns in df_select.columns:\n",
    "    if columns in feature_col:\n",
    "        df_select = df_select.withColumn(columns,df_select[columns].cast('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_select.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecAssembler = VectorAssembler(inputCols=feature_col, outputCol=\"smart_1N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = vecAssembler.setHandleInvalid(\"skip\").transform(df_select).select('model','serial_number', 'smart_1N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(inputCol=\"smart_1N\", outputCol=\"scaledFeatures\", withStd=True, withMean=False)\n",
    "scalerModel = scaler.fit(data)\n",
    "cluster_data = scalerModel.transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "kmeans = KMeans().setK(k).setSeed(1).setFeaturesCol(\"smart_1N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = kmeans.fit(cluster_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = model.clusterCenters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 79.93828738360416, 1: 200.0, 2: 116.165934602245, 3: 100.3403902034039}\n"
     ]
    }
   ],
   "source": [
    "#centers = [center.tolist() for center in centers]\n",
    "centroids={}\n",
    "i=0\n",
    "for center in centers:\n",
    "    centroids[i]=center[0]\n",
    "    i+=1\n",
    "print(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = model.transform(cluster_data).select('serial_number','smart_1N','prediction')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+----------+-----------------+\n",
      "| serial_number|smart_1N|prediction|           center|\n",
      "+--------------+--------+----------+-----------------+\n",
      "|      Z302715R| [120.0]|         2| 116.165934602245|\n",
      "|PL2331LAHBTVUJ| [100.0]|         3|100.3403902034039|\n",
      "|      ZA13WRL1|  [81.0]|         0|79.93828738360416|\n",
      "|      ZA16RT31|  [81.0]|         0|79.93828738360416|\n",
      "|      Z30250EB| [117.0]|         2| 116.165934602245|\n",
      "|      ZA14DL00|  [84.0]|         0|79.93828738360416|\n",
      "|      ZJV2EEFV|  [84.0]|         0|79.93828738360416|\n",
      "|      ZA11TV4X|  [78.0]|         0|79.93828738360416|\n",
      "|      VKGK8HPX| [100.0]|         3|100.3403902034039|\n",
      "|      ZCH080YV|  [83.0]|         0|79.93828738360416|\n",
      "|      S301LD67| [109.0]|         2| 116.165934602245|\n",
      "|      ZCH07CGA|  [79.0]|         0|79.93828738360416|\n",
      "|      Z304HKCN| [119.0]|         2| 116.165934602245|\n",
      "|      ZA12KEFN|  [83.0]|         0|79.93828738360416|\n",
      "|PL2331LAHB7SEJ| [100.0]|         3|100.3403902034039|\n",
      "|      ZJV2E76S|  [83.0]|         0|79.93828738360416|\n",
      "|      ZCH06D6Q|  [84.0]|         0|79.93828738360416|\n",
      "|      ZA21AGC6|  [79.0]|         0|79.93828738360416|\n",
      "|      ZCH0722E|  [77.0]|         0|79.93828738360416|\n",
      "|      Z305D65P| [115.0]|         2| 116.165934602245|\n",
      "+--------------+--------+----------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#transforming the values based on the centers\n",
    "\n",
    "transformed_pred=transformed.withColumn('center',when(transformed.prediction==0,centroids[0]) \\\n",
    "                                    .when(transformed.prediction==1,centroids[1]) \\\n",
    "                                    .when(transformed.prediction==2,centroids[2]) \\\n",
    "                                    .when(transformed.prediction==3,centroids[3]) )\n",
    "                                  \n",
    "transformed_pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+----------+-----------------+--------------------+------------------+\n",
      "| serial_number|smart_1N|prediction|           center|               model|smart_1_normalized|\n",
      "+--------------+--------+----------+-----------------+--------------------+------------------+\n",
      "|      Z302715R| [120.0]|         2| 116.165934602245|         ST4000DM000|             120.0|\n",
      "|PL2331LAHBTVUJ| [100.0]|         3|100.3403902034039|HGST HMS5C4040BLE640|             100.0|\n",
      "|      ZA13WRL1|  [81.0]|         0|79.93828738360416|        ST8000NM0055|              81.0|\n",
      "|      ZA16RT31|  [81.0]|         0|79.93828738360416|        ST8000NM0055|              81.0|\n",
      "|      Z30250EB| [117.0]|         2| 116.165934602245|         ST4000DM000|             117.0|\n",
      "+--------------+--------+----------+-----------------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now lest join the data frames on the basis of the serial number column and calculate distance with the cluster centers\n",
    "\n",
    "df_joined = transformed_pred.join(df_select, 'serial_number')\n",
    "df_joined.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+----------+-----------------+--------------------+------------------+-------------------+\n",
      "| serial_number|smart_1N|prediction|           center|               model|smart_1_normalized|           distance|\n",
      "+--------------+--------+----------+-----------------+--------------------+------------------+-------------------+\n",
      "|      Z302715R| [120.0]|         2| 116.165934602245|         ST4000DM000|             120.0| 3.8340653977549977|\n",
      "|PL2331LAHBTVUJ| [100.0]|         3|100.3403902034039|HGST HMS5C4040BLE640|             100.0|0.34039020340389925|\n",
      "|      ZA13WRL1|  [81.0]|         0|79.93828738360416|        ST8000NM0055|              81.0| 1.0617126163958375|\n",
      "|      ZA16RT31|  [81.0]|         0|79.93828738360416|        ST8000NM0055|              81.0| 1.0617126163958375|\n",
      "|      Z30250EB| [117.0]|         2| 116.165934602245|         ST4000DM000|             117.0| 0.8340653977549977|\n",
      "+--------------+--------+----------+-----------------+--------------------+------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now lets store the distance between cluster centers and the column\n",
    "distance=df_joined.withColumn('distance',abs(col('smart_1_normalized')-col('center')))\n",
    "distance.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the max distance for every cluster center to find the threshold creating a column named distance\n",
    "threshold=distance.groupBy('prediction').max('distance').withColumnRenamed(\"max(distance)\",\"maxDistance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|prediction|       maxDistance|\n",
      "+----------+------------------+\n",
      "|         2|16.165934602245002|\n",
      "|         3|  32.3403902034039|\n",
      "+----------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold.createOrReplaceTempView(\"threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance.createOrReplaceTempView(\"distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+------------------+---------+\n",
      "|prediction|smart_1N|          distance|IsAnomaly|\n",
      "+----------+--------+------------------+---------+\n",
      "|         0|  [81.0]|1.0617126163958375|    False|\n",
      "|         0|  [81.0]|1.0617126163958375|    False|\n",
      "|         0|  [84.0]|4.0617126163958375|    False|\n",
      "|         0|  [84.0]|4.0617126163958375|    False|\n",
      "|         0|  [78.0]|1.9382873836041625|    False|\n",
      "+----------+--------+------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classifying every thing having distnace more than 50% of the max distance as anomaly\n",
    "anomaly=spark.sql(\"select d.prediction,d.smart_1N,d.distance, IF(m.maxDistance*0.5<d.distance,'True','False') as IsAnomaly  from threshold m inner join distance d \\\n",
    "                          on m.prediction=d.prediction\")\n",
    "anomaly.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+---------+\n",
      "|          distance|prediction|IsAnomaly|\n",
      "+------------------+----------+---------+\n",
      "|  32.3403902034039|         3|     True|\n",
      "|  25.3403902034039|         3|     True|\n",
      "|  23.3403902034039|         3|     True|\n",
      "|  21.3403902034039|         3|     True|\n",
      "|20.061712616395837|         0|     True|\n",
      "+------------------+----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "anomaly.createOrReplaceTempView(\"anomaly\")\n",
    "anomaly_count=spark.sql(\"select a.distance,a.prediction,a.IsAnomaly from anomaly a where a.IsAnomaly=True order by distance desc\")\n",
    "anomaly_count.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomaly_count.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
